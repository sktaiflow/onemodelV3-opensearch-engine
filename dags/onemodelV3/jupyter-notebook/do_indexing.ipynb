{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skt.gcp import (\n",
    "    PROJECT_ID,\n",
    "    bq_insert_overwrite,\n",
    "    bq_to_df,\n",
    "    bq_to_pandas,\n",
    "    get_bigquery_client,\n",
    "    bq_table_exists,\n",
    "    get_max_part,\n",
    "    load_query_result_to_table,\n",
    "    pandas_to_bq,\n",
    "    pandas_to_bq_table,\n",
    "    load_bigquery_ipython_magic,\n",
    "    get_bigquery_client,\n",
    "    _print_query_job_results,\n",
    "    load_query_result_to_partitions\n",
    "    \n",
    ")\n",
    "\n",
    "from skt.ye import (\n",
    "    get_hdfs_conn,\n",
    "    get_spark,\n",
    "    hive_execute,\n",
    "    hive_to_pandas,\n",
    "    pandas_to_parquet,\n",
    "    slack_send\n",
    ")\n",
    "from skt.github_utils import GithubUtil\n",
    "from skt.vault_utils import get_secrets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, datetime, timedelta\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from pyhive import hive\n",
    "\n",
    "from copy import deepcopy\n",
    "from joblib import Parallel, delayed\n",
    "import os\n",
    "import sys\n",
    "from git import Repo\n",
    "from contextlib import contextmanager\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "secrets = get_secrets('github/sktaiflow')\n",
    "token = secrets['token']\n",
    "\n",
    "proxies = {\n",
    "    'http': secrets['proxy'],\n",
    "    'https': secrets['proxy'],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer func for cloning git modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def proxy(proxies):\n",
    "    env_backup = dict(os.environ)\n",
    "    os.environ[\"HTTP_PROXY\"] = proxies[\"http\"]\n",
    "    os.environ[\"HTTPS_PROXY\"] = proxies[\"https\"]\n",
    "    yield\n",
    "    os.environ.clear()\n",
    "    os.environ.update(env_backup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slack_sending(channel_name:str, msg:str=\"test\", is_adot:bool=True):\n",
    "    if \"#\" not  in channel_name:\n",
    "        channel_name += \"#\" + channel_name\n",
    "\n",
    "    slack_send(\n",
    "        text=msg,\n",
    "        username=\"SKT\",\n",
    "        channel=channel_name,\n",
    "        icon_emoji=\":large_blue_circle:\",\n",
    "        blocks=None,\n",
    "        dataframe=False,\n",
    "        adot=is_adot\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GithubUtil_custom(GithubUtil):\n",
    "    def __init__(self, token, proxies, **kwargs):\n",
    "        super().__init__(token, proxies)\n",
    "    \n",
    "    def clone_from_repo(self, git_url, branch=\"main\", git_save_path=\"/temp\"):\n",
    "        try:\n",
    "            if self._proxies:\n",
    "                with proxy(self._proxies):\n",
    "                    response = Repo.clone_from(git_url, git_save_path, branch=branch)\n",
    "                    return response\n",
    "            else:\n",
    "                msg = f\"proxy must be passed\"\n",
    "                raise Exception(msg)    \n",
    "        except Exception as e:\n",
    "            msg = f\"cloning git repo:{git_url} branch:{branch} failed {e}\"\n",
    "            slack_sending(msg=msg, channel_name=channel_name, is_adot=True)\n",
    "            raise Exception(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = GithubUtil_custom.clone_from_repo(git_url=git_url, branch=branch, save_path=git_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "module_path = os.path.join(git_save_path, \"dags/onemodelV3\")\n",
    "sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import from module\n",
    "from opensearch_engine.indexing_engine.preprocessor import OpensearchPreprocessor\n",
    "from opensearch_engine.indexing_engine.func import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get file list\n",
    "def get_gzip_files(directory='./temp/indexing/input'):\n",
    "    from pathlib import Path\n",
    "    gzip_files = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith(\".gzip\"):\n",
    "                file_path = os.path.join(root, file)\n",
    "                gzip_files.append(file_path)\n",
    "\n",
    "    return gzip_files\n",
    "\n",
    "file_list = get_gzip_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in file_list:\n",
    "    dataset = OpensearchPreprocessor.load(file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
